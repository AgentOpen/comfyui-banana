import base64
import io
import torch
import numpy as np
from PIL import Image
import re

class BananaBase64ToImage:
    """
    Bananaç‰ˆæœ¬çš„Base64è½¬å›¾åƒèŠ‚ç‚¹
    """

    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "base64_string": ("STRING", {
                    "multiline": True,
                    "default": "",
                    "placeholder": "ç²˜è´´base64ç¼–ç æˆ–åŒ…å«base64çš„æ–‡æœ¬"
                }),
            },
            "optional": {
                "mode": (["auto", "RGB", "RGBA"], {
                    "default": "auto"
                }),
            }
        }

    RETURN_TYPES = ("IMAGE", "MASK", "STRING")
    RETURN_NAMES = ("image", "mask", "info")
    FUNCTION = "decode_base64"
    CATEGORY = "ğŸŒ Banana/Image"
    OUTPUT_NODE = False

    def decode_base64(self, base64_string, mode="auto"):
        """
        ä»æ–‡æœ¬ä¸­æå–Base64ç¼–ç å¹¶è§£ç ä¸ºå›¾åƒ
        """
        if not base64_string.strip():
            raise ValueError("è¾“å…¥æ–‡æœ¬ä¸èƒ½ä¸ºç©º")

        try:
            # ä»æ··åˆæ–‡æœ¬ä¸­æå–base64ç¼–ç 
            clean_base64_data = self.extract_base64_from_text(base64_string)

            if not clean_base64_data:
                raise ValueError("æœªåœ¨æ–‡æœ¬ä¸­æ‰¾åˆ°æœ‰æ•ˆçš„base64å›¾åƒç¼–ç ")

            # è§£ç Base64
            image_data = base64.b64decode(clean_base64_data)

            # ä½¿ç”¨PILæ‰“å¼€å›¾åƒ
            image = Image.open(io.BytesIO(image_data))

            # å¤„ç†å›¾åƒæ¨¡å¼
            image, has_alpha = self.process_image_mode(image, mode)

            # è½¬æ¢ä¸ºComfyUIæ ¼å¼
            image_tensor = self.pil_to_tensor(image)

            # ç”Ÿæˆæ©ç 
            mask_tensor = self.generate_mask(image, has_alpha)

            info_text = f"è§£ç æˆåŠŸ: {image.size[0]}x{image.size[1]}, æ¨¡å¼: {image.mode}"

            return (image_tensor, mask_tensor, info_text)

        except Exception as e:
            error_msg = f"Base64è§£ç å¤±è´¥: {str(e)}"
            raise ValueError(error_msg)

    def extract_base64_from_text(self, text):
        """ä»æ··åˆæ–‡æœ¬ä¸­æå–base64ç¼–ç éƒ¨åˆ†"""
        # ç§»é™¤æ‰€æœ‰ç©ºç™½å­—ç¬¦
        clean_text = re.sub(r'\s+', '', text)

        # æ¨¡å¼1: åŒ¹é…data URIæ ¼å¼
        data_uri_pattern = r'data:image/(?:png|jpeg|jpg|gif|webp);base64,([A-Za-z0-9+/=]+)'
        data_uri_match = re.search(data_uri_pattern, clean_text)

        if data_uri_match:
            return data_uri_match.group(1)

        # æ¨¡å¼2: åŒ¹é…é•¿base64å­—ç¬¦ä¸²
        base64_pattern = r'([A-Za-z0-9+/]{100,}={0,2})'
        base64_matches = re.findall(base64_pattern, clean_text)

        if base64_matches:
            base64_matches.sort(key=len, reverse=True)
            longest_match = base64_matches[0]
            try:
                base64.b64decode(longest_match)
                return longest_match
            except:
                pass

        # æ¨¡å¼3: æŸ¥æ‰¾base64,å‰ç¼€
        try:
            base64_index = clean_text.find('base64,')
            if base64_index != -1:
                potential_base64 = clean_text[base64_index + 7:]
                base64.b64decode(potential_base64)
                return potential_base64
        except:
            pass

        # æœ€åå°è¯•ç›´æ¥è§£ç æ•´ä¸ªæ–‡æœ¬
        try:
            base64.b64decode(clean_text)
            return clean_text
        except:
            pass

        return None

    def process_image_mode(self, image, mode):
        """å¤„ç†å›¾åƒæ¨¡å¼å’Œè½¬æ¢"""
        original_mode = image.mode
        has_alpha = original_mode in ('RGBA', 'LA', 'PA')

        if mode != "auto":
            if mode == "RGB" and has_alpha:
                image = image.convert('RGB')
                has_alpha = False
            elif mode == "RGBA" and not has_alpha:
                image = image.convert('RGBA')
                has_alpha = True
            else:
                image = image.convert(mode)
        else:
            # è‡ªåŠ¨æ¨¡å¼å¤„ç†
            if original_mode == 'P':
                image = image.convert('RGBA' if image.info.get('transparency') else 'RGB')
                has_alpha = image.mode == 'RGBA'
            elif original_mode in ('LA', 'PA'):
                image = image.convert('RGBA')
                has_alpha = True
            elif original_mode != 'RGB' and original_mode != 'RGBA':
                image = image.convert('RGB')
                has_alpha = False

        return image, has_alpha

    def pil_to_tensor(self, image):
        """PILå›¾åƒè½¬æ¢ä¸ºComfyUIå¼ é‡"""
        image_array = np.array(image).astype(np.float32) / 255.0

        # å¤„ç†å•é€šé“å›¾åƒ
        if len(image_array.shape) == 2:
            image_array = np.expand_dims(image_array, axis=-1)

        # è½¬æ¢ä¸º (1, H, W, C) æ ¼å¼
        if image_array.shape[-1] == 1:
            image_tensor = torch.from_numpy(image_array).unsqueeze(0)
        else:
            image_tensor = torch.from_numpy(image_array)[None,]

        return image_tensor

    def generate_mask(self, image, has_alpha):
        """ä»å›¾åƒç”Ÿæˆæ©ç """
        if has_alpha and image.mode == 'RGBA':
            # æå–Alphaé€šé“ä½œä¸ºæ©ç 
            alpha_array = np.array(image.split()[-1]).astype(np.float32) / 255.0
            mask_tensor = torch.from_numpy(alpha_array).unsqueeze(0).unsqueeze(-1)
        else:
            # åˆ›å»ºå…¨ç™½æ©ç 
            width, height = image.size
            mask_tensor = torch.ones((1, height, width, 1), dtype=torch.float32)

        return mask_tensor

# ComfyUIèŠ‚ç‚¹æ˜ å°„ - è¿™æ˜¯å…³é”®éƒ¨åˆ†ï¼
NODE_CLASS_MAPPINGS = {
    "BananaBase64ToImage": BananaBase64ToImage,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "BananaBase64ToImage": "ğŸŒ Base64 to Image",
}